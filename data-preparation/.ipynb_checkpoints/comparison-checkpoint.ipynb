{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cell-width control\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noise from random DGP, two way model, non-separate clean and noise, smaller dict (50000)\n",
    "model_class = \"model_class_5\"\n",
    "model_num = \"model_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/anaconda3/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.example import example_pb2\n",
    "\n",
    "#utils\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import struct\n",
    "import time\n",
    "from noise import *\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Concatenate, Dot, Embedding, LSTM, Conv1D, MaxPooling1D, Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(47)\n",
    "\n",
    "def get_data(filename, nc_dist, replace, corr_sample, separate, band_width, noise_candidate_path, dgp):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        filename (string): path to data file holding clean datapoints, i.e. clean (text, summ) pairs\n",
    "        nc_dist ((float, float)): (clean_ratio, noise_ratio) tuple describing the desired noise-clean \n",
    "                                    distribution in the output dataset, sum(nc_dist) = 1\n",
    "        replace (bool): whether or not to sample with replacement from clean\n",
    "        corr_sample (bool): whether to compare some of the orig summs and the noise summs to check for\n",
    "                            correspondence\n",
    "        separate (bool): whether to generate noise from a set of texts that is disjoint from the clean data\n",
    "        band_width (int): number of outputs of G per text\n",
    "        noise_candidate_path (string): path where the generated noise files are stored\n",
    "        dgp (string): which DGP is to be used for noise, e.g. \"generator\" or \"random\"\n",
    "    Returns:\n",
    "        data ((numpy array, numpy array)): (clean, noise) tuple of Nx2 arrays of (text, summ) datapoints \n",
    "                                            with noise\n",
    "    \"\"\"\n",
    "    if dgp == \"generator\":\n",
    "        #get all the bad indices\n",
    "        print('Get all the bad indices...')\n",
    "        alarm_log = {}\n",
    "        alarm_count = 0\n",
    "        count = 4\n",
    "        filenum_old = 'XXXXXX'\n",
    "        name_old = 'XXXXXX'\n",
    "        for name_new in sorted(os.listdir(noise_candidates_path)):\n",
    "            filenum_new = name_new[0:6]\n",
    "            if filenum_new == filenum_old:\n",
    "                count += 1\n",
    "            if filenum_new != filenum_old:\n",
    "                if count != 4:\n",
    "                    alarm_count += 1\n",
    "                    alarm_log[name_old] = count #collect all the bad keys with count\n",
    "                count = 1\n",
    "            filenum_old = filenum_new\n",
    "            name_old = name_new\n",
    "        all_bad_indices = [int(filename[0:6]) for filename in alarm_log.keys()] #now have all the bad indices\n",
    "        print('...done!')\n",
    "\n",
    "        #read in clean data\n",
    "        print('Reading clean data...')\n",
    "        text_summ_pairs = []\n",
    "        with open(filename, 'r') as data:\n",
    "            text = data.readline()\n",
    "            summ = data.readline()\n",
    "            while summ:\n",
    "                if len(text) > 2 and len(summ) > 2:\n",
    "                    text_summ_pairs.append([text[0:-1], summ[0:-1]])\n",
    "                text = data.readline()\n",
    "                summ = data.readline()\n",
    "        clean_2d = numpy.array(text_summ_pairs, dtype=object)\n",
    "        print('...done!')\n",
    "\n",
    "\n",
    "        #remove bad indices\n",
    "        print('Remove bad indices from clean data...')\n",
    "        mask = numpy.ones(clean_2d.shape[0], dtype='bool')\n",
    "        mask[all_bad_indices] = False\n",
    "        clean_2d = clean_2d[mask]\n",
    "        N_clean = clean_2d.shape[0]\n",
    "        print('...done!')\n",
    "\n",
    "        #pick indices of noise\n",
    "        print('Pick noise indices...')\n",
    "        clean_ratio, noise_ratio = nc_dist\n",
    "        if separate: #check whether to generate noise from texts disjoint from clean data\n",
    "            N_noise = int((N_clean*noise_ratio)) #calculate N_noise\n",
    "            #below make sure we have a separate set of indices for noise which we can delete later for the separate\n",
    "            #guarantee\n",
    "            noise_separate_indices = numpy.random.choice(N_clean, size = N_noise, replace=False)\n",
    "            noise_index_pool = numpy.copy(noise_separate_indices)\n",
    "            for i in range(1, band_width):\n",
    "                noise_index_pool = numpy.concatenate((noise_index_pool, noise_separate_indices + i))\n",
    "            assert noise_index_pool.shape[0] == N_noise*band_width, \"noise index pool smaller than expected\"\n",
    "            assert abs(((N_clean - N_noise)/N_clean) - clean_ratio) < 0.0001 \\\n",
    "            and abs((N_noise/N_clean) - noise_ratio) < 0.0001 \\\n",
    "            ,\"Something is wrong with N_noise\" #check that you calculated N_noise correctly\n",
    "        else:\n",
    "            N_noise = int((N_clean - N_clean*clean_ratio)/clean_ratio) #calculate N_noise\n",
    "            noise_index_pool = numpy.arange(N_clean*band_width)\n",
    "            assert abs(N_clean/(N_clean + N_noise) - clean_ratio) < 0.0001 \\\n",
    "                and abs(N_noise/(N_clean + N_noise) - noise_ratio) < 0.0001 \\\n",
    "                ,\"Something is wrong with N_noise\" #check that you calculated N_noise correctly\n",
    "        noise_summ_indices = numpy.random.choice(noise_index_pool, size=N_noise, replace=replace) #get indices \\\n",
    "            #in the range of N_clean*(band_width of generator run, i.e. number of outputs of G per text)\n",
    "        assert N_noise == len(noise_summ_indices), \"N_noise and len(selected_indices do not match)\"\n",
    "        print('...done!')\n",
    "\n",
    "        #read in candidate noise points\n",
    "        print('Read in candidate noise points...')\n",
    "        candidate_noise = []\n",
    "        for filename in sorted(os.listdir(noise_candidates_path)):\n",
    "            if int(filename[0:6]) not in all_bad_indices:\n",
    "                with open(noise_candidates_path+filename, 'r') as file:\n",
    "                    candidate_noise.append(file.read().replace('\\n', ' ')) #read file, trim \\n and add to cand. list\n",
    "        assert len(candidate_noise) == band_width*clean_2d.shape[0], \"less candidates than expected\"\n",
    "        print('...done!')\n",
    "\n",
    "        #preprocess clean data, i.e. remove <s> and </s>\n",
    "        print('Preprocess clean data, i.e. remove <s> and </s>...')\n",
    "        for i in range(N_clean):\n",
    "            clean_2d[i,1] = clean_2d[i,1].replace('<s> ', '')\n",
    "            clean_2d[i,1] = clean_2d[i,1].replace(' </s>', '')\n",
    "        print('...done!')\n",
    "\n",
    "        if corr_sample: #take some samples to sanity check that refs and generated summs correspond\n",
    "            print('Sanity check some examples..')\n",
    "            idx = numpy.random.choice(N_noise, size=10, replace=False)\n",
    "            for i in idx:\n",
    "                print('### '+str(i)+' ###')\n",
    "                print('reference summary '+':\\n'+clean_2d[(noise_summ_indices[i] // 4),1])\n",
    "                print('generated summary'+':\\n'+candidate_noise[i])\n",
    "            print('...done!')\n",
    "\n",
    "        #put data together\n",
    "        print('Put data together...')\n",
    "        noise_texts = clean_2d[(noise_summ_indices // 4),0]\n",
    "        print('noise_texts.shape[0]', noise_texts.shape[0])\n",
    "        noise_summs = numpy.array(candidate_noise)[noise_summ_indices]\n",
    "        print('noise_summs.shape[0]', noise_summs.shape[0])\n",
    "        noise_2d = numpy.stack((noise_texts,noise_summs), axis=-1)\n",
    "        assert noise_2d.shape[0] == N_noise and noise_2d.shape[1] == 2, \"the noise_2d shape does not check out\"\n",
    "        print('...done!')\n",
    "\n",
    "        #remove noise source texts from clean data if separate was selected\n",
    "        if separate: #delete inputs for noise from clean data\n",
    "            print('prior', clean_2d.shape)\n",
    "            clean_2d = numpy.delete(clean_2d, noise_separate_indices, axis=0)\n",
    "            print('after', clean_2d.shape)\n",
    "            #TODO: this might skrew up the dist in the case were an index appears multiple times in sel_ind\n",
    "\n",
    "        return clean_2d, noise_2d\n",
    "    \n",
    "    elif dgp == 'random':\n",
    "        #read in clean data\n",
    "        print('Reading clean data...')\n",
    "        text_summ_pairs = []\n",
    "        with open(filename, 'r') as data:\n",
    "            text = data.readline()\n",
    "            summ = data.readline()\n",
    "            while summ:\n",
    "                if len(text) > 2 and len(summ) > 2:\n",
    "                    text_summ_pairs.append([text[0:-1], summ[0:-1]])\n",
    "                text = data.readline()\n",
    "                summ = data.readline()\n",
    "        clean_2d = numpy.array(text_summ_pairs, dtype=object)\n",
    "        print('...done!')\n",
    "        \n",
    "        #read in candidate noise points\n",
    "        print('Read in candidate noise points...')\n",
    "        fractions = {\"switch-pairs\":0.25,\"sentence-switch-entire-bank\":0.25,\\\n",
    "                     \"sentence-switch-same-text-bank\":0.25,\"word-switch-entire-bank\":0.25}\n",
    "        clean_2d, noise_2d = noise_randomDGP(clean_2d, fractions, separate, nc_dist)\n",
    "        print('...done!')\n",
    "        \n",
    "        #preprocess clean data, i.e. remove <s> and </s>\n",
    "        print('Preprocess clean data, i.e. remove <s> and </s>...')\n",
    "        for i in range(clean_2d.shape[0]):\n",
    "            clean_2d[i,1] = clean_2d[i,1].replace('<s> ', '')\n",
    "            clean_2d[i,1] = clean_2d[i,1].replace(' </s>', '')\n",
    "        print('...done!')\n",
    "        \n",
    "        return clean_2d, noise_2d\n",
    "    else:\n",
    "        print('error: no valid DGP was selected')\n",
    "\n",
    "def prep_data(clean_2d, noise_2d, max_features, val_share, maxlen_text, maxlen_summ,\n",
    "              load_tok=False, tok_path=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        clean_2d (numpy array): Nx2 array of text summ tuples with clean points\n",
    "        noise_2d (numpy array): Nx2 array of text summ tuples with noise points\n",
    "        max_features (int): max number of words for tokenizer\n",
    "        val_share (float): share (< 1) of data that is to be used for validation\n",
    "        load_tok (bool): whether to load tokenizer or train from scratch\n",
    "        tok_path (string): path to stored tokenizer object\n",
    "        maxlen_text (int): max length of text after which to cut text\n",
    "        maxlen_summ (int): max length of summ after which to cut summ\n",
    "    Returns:\n",
    "        texts_train_seq (array): (N_clean+N_noise)*(1-val_share)xmaxlen_text array of seq text\n",
    "        summs_train_seq (array): (N_clean+N_noise)*(1-val_share)xmaxlen_summ array of seq summ\n",
    "        text_val_seq (array): (N_clean+N_noise)*(val_share)xmaxlen_text array of seq text\n",
    "        summs_val_seq (array): (N_clean+N_noise)*(val_share)xmaxlen_summ array of seq summ\n",
    "        tokenizer (tokenizer object): tokenizer object\n",
    "    \"\"\"\n",
    "    #split texts and summs\n",
    "    texts = numpy.append(clean_2d[:,0], noise_2d[:,0])\n",
    "    summs = numpy.append(clean_2d[:,1], noise_2d[:,1])\n",
    "    \n",
    "    #get targets\n",
    "    N_clean = clean_2d.shape[0]\n",
    "    N_noise = noise_2d.shape[0]\n",
    "    targets = numpy.append([0]*N_clean, [1]*N_noise)\n",
    "    \n",
    "    #permute targets and data in the same way\n",
    "    indices = numpy.random.choice(N_clean+N_noise, size=N_clean+N_noise, replace=False)\n",
    "    assert len(indices) == N_clean+N_noise, \"indices are less N_clean + N_noise\"\n",
    "    texts = texts[indices]\n",
    "    summs = summs[indices]\n",
    "    targets = targets[indices]\n",
    "    \n",
    "    #split data into train and test\n",
    "    split = int((N_clean+N_noise)*val_share)\n",
    "    texts_train = texts[split:]\n",
    "    summs_train = summs[split:]\n",
    "    targets_train = targets[split:]\n",
    "    texts_val = texts[:split]\n",
    "    summs_val = summs[:split]\n",
    "    targets_val = targets[:split]\n",
    "    print('train dist: ', numpy.mean(targets_train)) #just checking what the dists are after permute\n",
    "    print('val dist: ', numpy.mean(targets_val)) #just checking what the dists are after permute\n",
    "    \n",
    "    #train tokenizer\n",
    "    if load_tok:\n",
    "        with open(tok_path, 'rb') as handle:\n",
    "            tokenizer = pickle.load(handle)\n",
    "    else:\n",
    "        tokenizer = Tokenizer(num_words=max_features,\n",
    "                                   filters='#$%&()*+-/:;<=>@[\\\\]^_{|}~\\t\\n',\n",
    "                                   lower=True,\n",
    "                                   split=\" \",\n",
    "                                   char_level=False)\n",
    "        tokenizer.fit_on_texts(numpy.append(texts_train, summs_train))\n",
    "    \n",
    "    #sequentialize data\n",
    "    texts_train_seq = tokenizer.texts_to_sequences(texts_train)\n",
    "    summs_train_seq = tokenizer.texts_to_sequences(summs_train)\n",
    "    texts_val_seq = tokenizer.texts_to_sequences(texts_val)\n",
    "    summs_val_seq = tokenizer.texts_to_sequences(summs_val)\n",
    "    \n",
    "    #pad data\n",
    "    texts_train_seq = sequence.pad_sequences(texts_train_seq, maxlen=maxlen_text)\n",
    "    summs_train_seq = sequence.pad_sequences(summs_train_seq, maxlen=maxlen_summ)\n",
    "    texts_val_seq = sequence.pad_sequences(texts_val_seq, maxlen=maxlen_text)\n",
    "    summs_val_seq = sequence.pad_sequences(summs_val_seq, maxlen=maxlen_summ)\n",
    "    \n",
    "    return texts_train_seq, summs_train_seq, targets_train, texts_val_seq, summs_val_seq, targets_val, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = 50000\n",
    "maxlen_text = 400\n",
    "maxlen_summ = 80\n",
    "embedding_size = 100 #128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "epochs = 50\n",
    "\n",
    "#Saving?\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean data...\n",
      "...done!\n",
      "Read in candidate noise points...\n",
      "3342\n",
      "(3342,)\n",
      "(13368, 2)\n",
      "(3342, 2)\n",
      "...done!\n",
      "Preprocess clean data, i.e. remove <s> and </s>...\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "#filename = \"/home/oala/Documents/MT/data/datasets/finished_files/train.bin\"\n",
    "#noise_candidates_path = '/home/oala/Documents/MT/noising/4-beam-PGC-noise-on-train/pretrained_model_tf1.2.1/decode_train_400maxenc_4beam_35mindec_120maxdec_ckpt-238410/decoded/'\n",
    "filename = \"/home/donald/documents/MT/data/data-essentials-mini/finished_files/val.bin\"\n",
    "noise_candidates_path = ' '\n",
    "nc_dist = (0.5,0.5)\n",
    "replace = False\n",
    "corr_sample = False\n",
    "separate = False\n",
    "band_width = 4\n",
    "dgp = \"random\"\n",
    "clean_2d, noise_2d = get_data(filename, nc_dist, replace, corr_sample, separate, band_width,noise_candidates_path, dgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13368, 2)\n",
      "(13368, 2)\n",
      "[\"-lrb- cnn -rrb- to come back or not come back ? that is the question former wimbledon champion marion bartoli posed on twitter , prompting a raft of replies and retweets . the frenchwoman was crowned champion at the all england club in july 2013 , but announced her retirement a mere one month later due to persistent injury problems . but now it appears the former world no. 7 is pondering a return to the court , with eight-time grand slam champion jimmy connors warning bartoli to only consider it if she is fully committed . bartoli would n't be the first women 's star to come out of retirement . veterans martina hingis , jennifer capriati and kimiko date-krumm all chose to reenter the fray after saying their initial farewells . bartoli won eight wta titles during a 13-year professional career , reaching the quarterfinals of the australian and u.s. opens and the last four of her home grand slam in paris .\"\n",
      " 'marion bartoli asks whether she should make a comeback over twitter . she won wimbledon in 2013 but retired one month later due to injuries . bartoli won eight wta titles during a 13-year professional career .']\n",
      "[\"-lrb- cnn -rrb- to come back or not come back ? that is the question former wimbledon champion marion bartoli posed on twitter , prompting a raft of replies and retweets . the frenchwoman was crowned champion at the all england club in july 2013 , but announced her retirement a mere one month later due to persistent injury problems . but now it appears the former world no. 7 is pondering a return to the court , with eight-time grand slam champion jimmy connors warning bartoli to only consider it if she is fully committed . bartoli would n't be the first women 's star to come out of retirement . veterans martina hingis , jennifer capriati and kimiko date-krumm all chose to reenter the fray after saying their initial farewells . bartoli won eight wta titles during a 13-year professional career , reaching the quarterfinals of the australian and u.s. opens and the last four of her home grand slam in paris .\"\n",
      " 'staffers at the south carolina aquarium are treating a rare , 475-pound leatherback sea turtle . the turtle washed up saturday on a nearby beach and may be returned to the ocean soon .']\n"
     ]
    }
   ],
   "source": [
    "print(clean_2d.shape)\n",
    "print(noise_2d.shape)\n",
    "print(clean_2d[100])\n",
    "print(noise_2d[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dist:  0.4976857263079153\n",
      "val dist:  0.509257527585562\n"
     ]
    }
   ],
   "source": [
    "val_share = 0.2\n",
    "\n",
    "texts_train, summs_train, targets_train, texts_val, summs_val, targets_val, tokenizer = \\\n",
    "    prep_data(clean_2d, noise_2d, max_features, val_share, maxlen_text, maxlen_summ,\n",
    "              load_tok=False, tok_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#GLOVE_DIR = \"/home/oala/Documents/MT/data/datasets/glove.6B/\"\n",
    "GLOVE_DIR = \"/home/donald/documents/MT/data/data-essentials-mini/glove.6B/\"\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = numpy.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = numpy.zeros((len(word_index) + 1, embedding_size))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom embeddings layer\n",
    "embedding_layer_text = Embedding(len(word_index) + 1,\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length= maxlen_text,\n",
    "                            trainable=False)\n",
    "\n",
    "embedding_layer_summ = Embedding(len(word_index) + 1,\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length= maxlen_summ,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2way input\n",
    "text_input = Input(shape=(maxlen_text,), dtype='int32')\n",
    "summ_input = Input(shape=(maxlen_summ,), dtype='int32')\n",
    "\n",
    "#2way embeddings\n",
    "text_route = embedding_layer_text(text_input)\n",
    "summ_route = embedding_layer_summ(summ_input)\n",
    "\n",
    "#2way dropout\n",
    "text_route = Dropout(0.25)(text_route)\n",
    "summ_route = Dropout(0.25)(summ_route)\n",
    "\n",
    "#2way conv\n",
    "text_route = Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1)(text_route)\n",
    "summ_route = Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1)(summ_route)\n",
    "\n",
    "#2way max pool\n",
    "text_route = MaxPooling1D(pool_size=pool_size)(text_route)\n",
    "summ_route = MaxPooling1D(pool_size=pool_size)(summ_route)\n",
    "\n",
    "#2way lstm\n",
    "text_route = LSTM(lstm_output_size)(text_route)\n",
    "summ_route = LSTM(lstm_output_size)(summ_route)\n",
    "\n",
    "#merge both routes\n",
    "#merged = keras.layers.concatenate((text_route, summ_route), axis=-1)\n",
    "#merged = Concatenate(axis=-1)([text_route, summ_route])\n",
    "merged = Dot(axes=1,normalize=True)([text_route, summ_route])\n",
    "\n",
    "#output\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "#define model\n",
    "model = Model(inputs=[text_input, summ_input], outputs=[output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 21389 samples, validate on 5347 samples\n",
      "Epoch 1/50\n",
      "21389/21389 [==============================] - 98s 5ms/step - loss: 0.6812 - acc: 0.5640 - val_loss: 0.6539 - val_acc: 0.6273\n",
      "Epoch 2/50\n",
      "21389/21389 [==============================] - 94s 4ms/step - loss: 0.6428 - acc: 0.6397 - val_loss: 0.6248 - val_acc: 0.6641\n",
      "Epoch 3/50\n",
      "21389/21389 [==============================] - 91s 4ms/step - loss: 0.6061 - acc: 0.6824 - val_loss: 0.5796 - val_acc: 0.7094\n",
      "Epoch 4/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.5676 - acc: 0.7178 - val_loss: 0.5980 - val_acc: 0.6742\n",
      "Epoch 5/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.5255 - acc: 0.7521 - val_loss: 0.5294 - val_acc: 0.7466\n",
      "Epoch 6/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.4907 - acc: 0.7742 - val_loss: 0.5097 - val_acc: 0.7572\n",
      "Epoch 7/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.4620 - acc: 0.7928 - val_loss: 0.5008 - val_acc: 0.7599\n",
      "Epoch 8/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.4373 - acc: 0.8060 - val_loss: 0.4872 - val_acc: 0.7713\n",
      "Epoch 9/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.4170 - acc: 0.8194 - val_loss: 0.4773 - val_acc: 0.7696\n",
      "Epoch 10/50\n",
      "21389/21389 [==============================] - 88s 4ms/step - loss: 0.3988 - acc: 0.8282 - val_loss: 0.4729 - val_acc: 0.7739\n",
      "Epoch 11/50\n",
      "21389/21389 [==============================] - 88s 4ms/step - loss: 0.3834 - acc: 0.8387 - val_loss: 0.4837 - val_acc: 0.7720\n",
      "Epoch 12/50\n",
      "21389/21389 [==============================] - 88s 4ms/step - loss: 0.3684 - acc: 0.8453 - val_loss: 0.4912 - val_acc: 0.7638\n",
      "Epoch 13/50\n",
      "21389/21389 [==============================] - 87s 4ms/step - loss: 0.3546 - acc: 0.8535 - val_loss: 0.4893 - val_acc: 0.7733\n",
      "Epoch 14/50\n",
      "21389/21389 [==============================] - 88s 4ms/step - loss: 0.3414 - acc: 0.8568 - val_loss: 0.4937 - val_acc: 0.7765\n",
      "Epoch 15/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.3283 - acc: 0.8644 - val_loss: 0.4947 - val_acc: 0.7759\n",
      "Epoch 16/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.3133 - acc: 0.8724 - val_loss: 0.4965 - val_acc: 0.7745\n",
      "Epoch 17/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.3044 - acc: 0.8750 - val_loss: 0.4977 - val_acc: 0.7705\n",
      "Epoch 18/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2941 - acc: 0.8788 - val_loss: 0.5219 - val_acc: 0.7690\n",
      "Epoch 19/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2854 - acc: 0.8840 - val_loss: 0.5249 - val_acc: 0.7702\n",
      "Epoch 20/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2770 - acc: 0.8857 - val_loss: 0.5173 - val_acc: 0.7754\n",
      "Epoch 21/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2629 - acc: 0.8919 - val_loss: 0.5428 - val_acc: 0.7625\n",
      "Epoch 22/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2545 - acc: 0.8963 - val_loss: 0.5383 - val_acc: 0.7668\n",
      "Epoch 23/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2509 - acc: 0.8978 - val_loss: 0.5508 - val_acc: 0.7621\n",
      "Epoch 24/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2417 - acc: 0.9007 - val_loss: 0.5578 - val_acc: 0.7705\n",
      "Epoch 25/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2343 - acc: 0.9061 - val_loss: 0.5760 - val_acc: 0.7556\n",
      "Epoch 26/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2290 - acc: 0.9076 - val_loss: 0.5672 - val_acc: 0.7688\n",
      "Epoch 27/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2206 - acc: 0.9115 - val_loss: 0.5870 - val_acc: 0.7653\n",
      "Epoch 28/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.2172 - acc: 0.9143 - val_loss: 0.6146 - val_acc: 0.7619\n",
      "Epoch 29/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2065 - acc: 0.9169 - val_loss: 0.5956 - val_acc: 0.7604\n",
      "Epoch 30/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2032 - acc: 0.9207 - val_loss: 0.6113 - val_acc: 0.7572\n",
      "Epoch 31/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.2004 - acc: 0.9172 - val_loss: 0.6234 - val_acc: 0.7670\n",
      "Epoch 32/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1907 - acc: 0.9239 - val_loss: 0.6565 - val_acc: 0.7601\n",
      "Epoch 33/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1914 - acc: 0.9240 - val_loss: 0.6403 - val_acc: 0.7535\n",
      "Epoch 34/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1860 - acc: 0.9258 - val_loss: 0.6826 - val_acc: 0.7614\n",
      "Epoch 35/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1813 - acc: 0.9267 - val_loss: 0.6696 - val_acc: 0.7548\n",
      "Epoch 36/50\n",
      "21389/21389 [==============================] - 91s 4ms/step - loss: 0.1769 - acc: 0.9309 - val_loss: 0.6877 - val_acc: 0.7576\n",
      "Epoch 37/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1761 - acc: 0.9274 - val_loss: 0.6943 - val_acc: 0.7565\n",
      "Epoch 38/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1677 - acc: 0.9339 - val_loss: 0.7235 - val_acc: 0.7546\n",
      "Epoch 39/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1671 - acc: 0.9337 - val_loss: 0.7260 - val_acc: 0.7488\n",
      "Epoch 40/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1701 - acc: 0.9337 - val_loss: 0.7061 - val_acc: 0.7531\n",
      "Epoch 41/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1629 - acc: 0.9352 - val_loss: 0.7154 - val_acc: 0.7593\n",
      "Epoch 42/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1530 - acc: 0.9393 - val_loss: 0.7111 - val_acc: 0.7513\n",
      "Epoch 43/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1595 - acc: 0.9369 - val_loss: 0.7379 - val_acc: 0.7490\n",
      "Epoch 44/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1528 - acc: 0.9402 - val_loss: 0.7392 - val_acc: 0.7514\n",
      "Epoch 45/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1494 - acc: 0.9417 - val_loss: 0.7579 - val_acc: 0.7563\n",
      "Epoch 46/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1587 - acc: 0.9360 - val_loss: 0.7331 - val_acc: 0.7490\n",
      "Epoch 47/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1474 - acc: 0.9419 - val_loss: 0.7759 - val_acc: 0.7589\n",
      "Epoch 48/50\n",
      "21389/21389 [==============================] - 90s 4ms/step - loss: 0.1428 - acc: 0.9455 - val_loss: 0.7697 - val_acc: 0.7503\n",
      "Epoch 49/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1414 - acc: 0.9455 - val_loss: 0.7902 - val_acc: 0.7481\n",
      "Epoch 50/50\n",
      "21389/21389 [==============================] - 89s 4ms/step - loss: 0.1440 - acc: 0.9433 - val_loss: 0.7927 - val_acc: 0.7498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f4347c8d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit([texts_train, summs_train], targets_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=([texts_val, summs_val], targets_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_string = \"gary d. cohn , president trump’s top economic adviser , said on tuesday that he would resign , becoming the latest in a series of high-profile departures from the trump administration . white house officials insisted that there was no single factor behind the departure of mr. cohn , who heads the national economic council . but his decision to leave came as he seemed poised to lose an internal struggle over mr. trump’s plan to impose large tariffs on steel and aluminum imports. mr. cohn had warned last week that he might resign if mr. trump followed through with the tariffs, which mr. cohn had lobbied against internally .  “ gary has been my chief economic adviser and did a superb job in driving our agenda , helping to deliver historic tax cuts and reforms and unleashing the american economy once again , ” mr. trump said in a statement to the new york times . “ he is a rare talent , and i thank him for his dedicated service to the american people . ”  mr. cohn is expected to leave in the coming weeks. he will join a string of recent departures by senior white house officials, including mr. trump’s communications director and a powerful staff secretary.  yet the departure of mr. cohn , a free-trade-oriented democrat who fended off a number of nationalist-minded policies during his year in the trump administration , could have a ripple effect on the president’s economic decisions and on the financial industry .  it leaves mr. trump surrounded primarily by advisers with strong protectionist views who advocate the types of aggressive trade measures , like tariffs , that mr. trump campaigned on but that mr. cohn fought inside the white house . mr. cohn was viewed by republican lawmakers as the steady hand who could prevent mr. trump from engaging in activities that could trigger a trade war.  even the mere threat , last august , that mr. cohn might leave sent the financial markets tumbling. on tuesday , mr. cohn’s announcement rattled markets , and trading in futures pointed to a decline in the united states stock market when it opened on wednesday .  in a statement , mr. cohn said he had been pleased to work on “pro-growth economic policies to benefit the american people , in particular the passage of historic tax reform . ” white house officials said that mr. cohn was leaving on cordial terms with the president and that they planned to discuss policy even after his departure .  mr. cohn’s departure comes as the white house has been buffeted by turnover , uncertainty and internal divisions and as the president lashes out at the special counsel investigation that seems to be bearing down on his team .  a host of top aides have been streaming out the white house door or are considering a departure . rob porter , the white house staff secretary and a member of the inner circle , resigned after spousal abuse allegations . hope hicks , the president’s communications director and confidante , announced that she would leave soon . in recent days , the president has lost a speechwriter , an associate attorney general and the north korea negotiator .  others are perpetually seen as on the way out . john f. kelly , the chief of staff , at one point broached resigning over the handling of mr. porter’s case . lt. gen. h. r. mcmaster , the national security adviser , has been reported to be preparing to leave . and many officials wonder if jared kushner , the president’s son-in-law and senior adviser , will stay now that he has lost his top-secret security clearance; the departure of mr. cohn further shrinks the number of allies mr. kushner and his wife , ivanka trump , have in the white house .  more than one in three top white house officials left by the end of mr. trump’s first year and fewer than half of the 12 positions closest to the president are still occupied by the same people as when he came into office , according to a brookings institution study .  mr. cohn’s departure will bring the turnover number to 43 percent , according to updated figures compiled by kathryn dunn tenpas of the brookings institution .  for all the swings of the west wing revolving door over the last year , mr. cohn’s decision to leave struck a different chord for people . he is among the most senior officials to resign to date .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_string = \"gary d. cohn , president trump’s top economic adviser , said on tuesday that he would resign . more than one in three top white house officials left by the end of mr. trump’s first year .\"\n",
    "summ_string = \"angela merkel visited president trump last wednesday . they talked about the iran deal and trade . president trump will travel on to europe next week .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_text = sequence.pad_sequences(tokenizer.texts_to_sequences([text_string]), maxlen=maxlen_text)\n",
    "predict_summ = sequence.pad_sequences(tokenizer.texts_to_sequences([summ_string]), maxlen=maxlen_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10397304]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([predict_text, predict_summ], batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5006487004223084"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(targets_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tok_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir, listdir\n",
    "#read in article texts, baseline summs, m1 summs, m2 summs and ref summs\n",
    "\n",
    "article_dir = \"/home/oala/Documents/MT/data/datasets/finished_files/test_output/articles/\"\n",
    "reference_dir = \"/home/oala/Documents/MT/data/datasets/finished_files/test_output/reference/\"\n",
    "baseline_dir = \"/home/oala/Documents/MT/data/datasets/finished_files/test_output/baseline/\"\n",
    "pointergen_dir = \"/home/oala/Documents/MT/data/datasets/finished_files/test_output/pointer-gen/\"\n",
    "pointergencov_dir = \"/home/oala/Documents/MT/data/datasets/finished_files/test_output/pointer-gen-cov/\"\n",
    "\n",
    "article_files = listdir(article_dir)\n",
    "article_files.sort()\n",
    "reference_files = listdir(reference_dir)\n",
    "reference_files.sort()\n",
    "baseline_files = listdir(baseline_dir)\n",
    "baseline_files.sort()\n",
    "pointergen_files = listdir(pointergen_dir)\n",
    "pointergen_files.sort()\n",
    "pointergencov_files = listdir(pointergencov_dir)\n",
    "pointergencov_files.sort()\n",
    "\n",
    "#read in texts\n",
    "texts = []\n",
    "for txt_file in article_files:\n",
    "    with open(article_dir+txt_file,'r',encoding='utf-8', errors='ignore') as txt:\n",
    "        text = txt.read()\n",
    "        text = text.replace('(', '-lrb-')\n",
    "        text = text.replace(')', '-rrb-')\n",
    "        text = text.replace('[', '-lsb-')\n",
    "        text = text.replace(']', '-rsb-')\n",
    "        text = text.replace('{', '-lcb-')\n",
    "        text = text.replace('}', '-rcb-')\n",
    "        texts.append(text)\n",
    "texts = numpy.array(texts)\n",
    "texts_text = numpy.copy(texts)\n",
    "texts = tokenizer.texts_to_sequences(texts)\n",
    "texts = sequence.pad_sequences(texts, maxlen=maxlen_text)\n",
    "\n",
    "#helper functions for summs\n",
    "def summ_dir2array(dir_name, file_list):\n",
    "    summs = []\n",
    "    for txt_file in file_list:\n",
    "        with open(dir_name+txt_file,'r',encoding='utf-8', errors='ignore') as txt:\n",
    "            summ = \"\"\n",
    "            line = txt.readline()\n",
    "            while line:\n",
    "                line = line.replace('\\n', ' ')\n",
    "                line = line.replace('(', '-lrb-')\n",
    "                line = line.replace(')', '-rrb-')\n",
    "                line = line.replace('[', '-lsb-')\n",
    "                line = line.replace(']', '-rsb-')\n",
    "                line = line.replace('{', '-lcb-')\n",
    "                line = line.replace('}', '-rcb-')\n",
    "                \n",
    "                summ += line\n",
    "                line = txt.readline()\n",
    "\n",
    "            summs.append(summ)\n",
    "    summs = numpy.array(summs)\n",
    "    summs_text = numpy.copy(summs)\n",
    "    summs = tokenizer.texts_to_sequences(summs)\n",
    "    summs = sequence.pad_sequences(summs, maxlen=maxlen_summ)\n",
    "    \n",
    "    return summs, summs_text\n",
    "\n",
    "#reference summs\n",
    "reference_summs, reference_summs_text = summ_dir2array(reference_dir, reference_files)\n",
    "\n",
    "#baseline summs\n",
    "baseline_summs, baseline_summs_text = summ_dir2array(baseline_dir, baseline_files)\n",
    "\n",
    "#pointergen summs\n",
    "pointergen_summs, pointergen_summs_text = summ_dir2array(pointergen_dir, pointergen_files)\n",
    "\n",
    "#pointergencov summs\n",
    "pointergencov_summs, pointergencov_summs_text = summ_dir2array(pointergencov_dir, pointergencov_files)\n",
    "\n",
    "N = len(texts_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490/11490 [==============================] - 7s 618us/step\n",
      "11490/11490 [==============================] - 7s 620us/step\n",
      "[0.3157948085323326, 0.8859878072695072]\n",
      "0.11401218450826806\n"
     ]
    }
   ],
   "source": [
    "#reference\n",
    "reference_preds = model.predict([texts, reference_summs], batch_size=batch_size, verbose=1)\n",
    "print(model.evaluate([texts, reference_summs],[0]*texts.shape[0], batch_size=batch_size))\n",
    "\n",
    "reference_preds_flat = numpy.ndarray.flatten(reference_preds)\n",
    "reference_preds_onehot = numpy.copy(reference_preds_flat)\n",
    "reference_preds_onehot[reference_preds_onehot<0.5]=0\n",
    "reference_preds_onehot[reference_preds_onehot>=0.5]=1\n",
    "#reference_preds_onehot[reference_preds_onehot<0.02]=0\n",
    "#reference_preds_onehot[reference_preds_onehot>=0.02]=1\n",
    "print(sum(reference_preds_onehot)/reference_preds_onehot.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490/11490 [==============================] - 7s 616us/step\n",
      "0.18398607484769364\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "baseline_preds = model.predict([texts, baseline_summs], batch_size=batch_size, verbose=1)\n",
    "\n",
    "baseline_preds_flat = numpy.ndarray.flatten(baseline_preds)\n",
    "baseline_preds_onehot = numpy.copy(baseline_preds_flat)\n",
    "baseline_preds_onehot[baseline_preds_onehot<0.5]=0\n",
    "baseline_preds_onehot[baseline_preds_onehot>=0.5]=1\n",
    "#baseline_preds_onehot[baseline_preds_onehot<0.02]=0\n",
    "#baseline_preds_onehot[baseline_preds_onehot>=0.02]=1\n",
    "print(sum(baseline_preds_onehot)/baseline_preds_onehot.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490/11490 [==============================] - 7s 624us/step\n",
      "0.2614447345517842\n"
     ]
    }
   ],
   "source": [
    "#pointergen\n",
    "pointergen_preds = model.predict([texts, pointergen_summs], batch_size=batch_size, verbose=1)\n",
    "\n",
    "pointergen_preds_flat = numpy.ndarray.flatten(pointergen_preds)\n",
    "pointergen_preds_onehot = numpy.copy(pointergen_preds_flat)\n",
    "pointergen_preds_onehot[pointergen_preds_onehot<0.5]=0\n",
    "pointergen_preds_onehot[pointergen_preds_onehot>=0.5]=1\n",
    "#pointergen_preds_onehot[pointergen_preds_onehot<0.02]=0\n",
    "#pointergen_preds_onehot[pointergen_preds_onehot>=0.02]=1\n",
    "print(sum(pointergen_preds_onehot)/pointergen_preds_onehot.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490/11490 [==============================] - 7s 619us/step\n",
      "0.37885117493472587\n"
     ]
    }
   ],
   "source": [
    "#pointergencov\n",
    "pointergencov_preds = model.predict([texts, pointergencov_summs], batch_size=batch_size, verbose=1)\n",
    "\n",
    "pointergencov_preds_flat = numpy.ndarray.flatten(pointergencov_preds)\n",
    "pointergencov_preds_onehot = numpy.copy(pointergencov_preds_flat)\n",
    "pointergencov_preds_onehot[pointergencov_preds_onehot<0.5]=0\n",
    "pointergencov_preds_onehot[pointergencov_preds_onehot>=0.5]=1\n",
    "#pointergencov_preds_onehot[pointergencov_preds_onehot<0.02]=0\n",
    "#pointergencov_preds_onehot[pointergencov_preds_onehot>=0.02]=1\n",
    "print(sum(pointergencov_preds_onehot)/pointergencov_preds_onehot.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    model.save('%s_%s.h5' % (model_class,model_num))\n",
    "    with open('%s_%s_TOKENIZER.pickle' % (model_class,model_num), 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nepal civil war aftermath inspired maggie doyne to help children . doyne 's blinknow foundation supports a home for 50 children and a school that educates hundreds more . do you know a hero ? nominations are open for 2015 cnn heroes .\n",
      "surkhet , nepal -lrb- cnn -rrb- ten years ago , with her high school diploma and a backpack , maggie doyne left her new jersey hometown to travel the world before college . she lived in a buddhist monastery , helped rebuild a sea wall in fiji , then went to india and worked with nepalese refugees . there , she met a young girl who wanted to find her family in nepal . doyne went with her . that 's when doyne 's life took an unexpected turn . do you know a hero ? nominations are open for cnn heroes 2015 . a decade-long civil war had just ended in the country , and doyne witnessed its effects firsthand . she met women and children who were suffering , struggling to survive . `` it changed me , '' said doyne , now 28 . `` there were children with mallets that would go into the riverbed , pick up a big stone and break it into little , little pieces -lrb- to sell -rrb- . and they were doing that all day , every day . '' doyne called her parents and asked them to wire her the $ 5,000 she had earned babysitting . in 2006 , she purchased land in surkhet , a district in western nepal . she worked for two years with the local community to build the kopila valley children 's home . today , kopila -- which means `` flower bud '' in nepali -- is home to about 50 children , from infants to teenagers . doyne started the blinknow foundation to support and grow her efforts . in 2010 , the group opened its kopila valley school , which today educates more than 350 students . doyne lives in nepal year-round , traveling to the u.s. a few times a year . see more cnn heroes . the cnn heroes team traveled to surkhet and talked to doyne about her work and the community she supports . below is an edited version of their conversation . cnn : how does it work , raising nearly 50 kids ? maggie doyne : it 's communal living , for sure ! we 're a family of almost 50 kids ages 8 months to 16 years . everybody just pitches in and helps each other . they all have their chores . they all have their duties . and everybody cooks the meals together and makes sure that they do their part to make the home run smoothly . the staff at the home , we call them the aunties and the uncles . we wake up in the morning and go off to school . and then come home and do homework and eat our meals together , and everybody goes to bed at night . cnn : how does a child come to live in your home ? doyne : our first priority as an organization is to keep a child with their family if at all possible . in order to come into the home , you need to have lost both parents , or in some rare cases have suffered extreme neglect , abuse or have a parent who 's incarcerated . we have to conduct a full investigation . so usually that involves going to the child 's village , making calls , doing police checks , getting documentation and paperwork . we have to dig up birth certificates , death certificates , make sure that everything lines up the way that they say it does . cnn : meanwhile , you have 350 children attending your school . what is their background ? doyne : every single year we 'll get from 1,000 to 1,500 applicants . and we choose the ones who are the most needful and really wo n't be in school without us . most of them live in one room , a mud hut . a lot of them are just in survival mode . we try to relieve the burden from the family , so that the child has food , medical care , books , zero fees for education . cnn : what have you learned working with the local community in nepal ? doyne : i learned very early on , from the beginning , that i could n't come in and just be like , `` here , i have a vision . this is what we 're going to do . '' that does n't work . it has to be slow ; it has to be organic . and it has to come from the community and be a `` we '' thing . it 's really important to me that this is a nepali project , working for nepal , for the community . so the faces that you see are strong nepali women and amazing nepali role-model men . cnn : how does the project continue to grow ? doyne : we started with the home and then school . we run the school lunch program . then we needed to keep our kids really healthy , so we started a small clinic and then a counseling center . from there we started getting more sustainable and growing our own food . and then from there we decided to start a women 's center . we just bought a new piece of property to create a totally green and sustainable off-the-grid campus . this year we converted to solar energy . so we 'll have a high school and then a day care , preschool , elementary , all the way up , and a vocational center where kids can become a thriving young adult with everything they need to succeed moving forward . it 's become so much more than just a little girl with a backpack and a big dream . it 's become a community . and i want to teach and have other people take this example and hope this sets a precedent for what our world can be and look like . want to get involved ? check out the blinknow foundation website at www.blinknow.org and see how to help .\n",
      "-lrb- cnn -rrb- one of the youngest suspects yet has been arrested on terror-related charges in england . a 14-year-old boy was taken into custody after encouraging an attack on an australian parade honoring the war dead and urging the beheading of `` someone in australia , '' deborah walsh , deputy head of counter terrorism at the crown prosecution service , said in a statement thursday . the teenager was taken into custody april 2 after uk 's greater manchester police examined electronic devices and discovered communications between the teen and a man in australia , police said in a statement . the teenager , arrested in blackburn , lancashire , was not named `` because of legal reasons , '' the statement said . he was charged with two counts of inciting another person to commit an act of terrorism overseas and will appear in westminster magistrate 's court on friday . he was communicating with suspects in operation rising , an australian law enforcement operation that apprehended several men suspected of planning terrorist actions , police in victoria , australia , said on the department website . australia : charges in foiled ` isis-inspired ' plot . those acts of terror were planned for anzac day -lrb- australia and new zealand army corps day -rrb- on friday , the centennial of the gallipoli campaign in world war i , police said . `` the first allegation is that , between 15 and 26 march 2015 , the defendant incited another person to commit an act of terrorism , namely to carry out an attack at an anzac parade in australia with the aim of killing and/or causing serious injury to people , '' walsh said . `` the second allegation is that on 18 march 2015 , the defendant incited another person to behead someone in australia . '' australian law enforcement officers arrested several people last weekend in operation rising . tuesday , victoria police and the australian federal police charged sevdet ramdan besim with conspiracy to commit acts done in preparation for , or planning , terrorist acts . authorities have not named the person with whom the 14-year-old in britain was communicating . british teens face terror charges after being detained en route to syria . cnn 's alexander felton contributed to this report .\n",
      "the 14-year-old had communicated with terror suspects in australia , authorities said . police : the teenager encouraged others to attack a parade and behead someone in australia .\n"
     ]
    }
   ],
   "source": [
    "print(reference_summs_text[500])\n",
    "print(texts_text[500])\n",
    "print(clean_2d[500,0])\n",
    "print(clean_2d[500,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on actual testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "model = load_model('/home/oala/Documents/MT/data/model-params/exciting-crazy/%s/%s/%s_%s.h5' % (model_class,model_num,model_class, model_num))\n",
    "tok_path= '/home/oala/Documents/MT/data/model-params/exciting-crazy/%s/%s/%s_%s_TOKENIZER.pickle' % (model_class,model_num,model_class,model_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100/0 (clean/noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean data...\n",
      "...done!\n",
      "Read in candidate noise points...\n",
      "2872\n",
      "(2872,)\n",
      "(11490, 2)\n",
      "(2872, 2)\n",
      "...done!\n",
      "Preprocess clean data, i.e. remove <s> and </s>...\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/oala/Documents/MT/data/datasets/finished_files/test.bin\"\n",
    "noise_candidates_path = '/home/oala/Documents/MT/noising/4-beam-PGC-noise-on-train/pretrained_model_tf1.2.1/decode_train_400maxenc_4beam_35mindec_120maxdec_ckpt-238410/decoded/'\n",
    "nc_dist = (0.5,0.5)\n",
    "replace = False\n",
    "corr_sample = False\n",
    "separate = False\n",
    "band_width = 4\n",
    "dgp = \"random\"\n",
    "clean_2d, noise_2d = get_data(filename, nc_dist, replace, corr_sample, separate, band_width,noise_candidates_path, dgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11490, 2)\n",
      "(11488, 2)\n"
     ]
    }
   ],
   "source": [
    "print(clean_2d.shape)\n",
    "print(noise_2d.shape)\n",
    "#clean_2d = clean_2d[0:2] #here you reduce clean to 2 datapoints to get only noise!\n",
    "noise_2d = noise_2d[0:2]\n",
    "val_share = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dist:  0.00010876658690450294\n",
      "val dist:  0.0004351610095735422\n"
     ]
    }
   ],
   "source": [
    "texts_train, summs_train, targets_train, texts_val, summs_val, targets_val, tokenizer = \\\n",
    "    prep_data(clean_2d, noise_2d, max_features, val_share, maxlen_text, maxlen_summ,\n",
    "              load_tok=True, tok_path=tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the splits to get all data\n",
    "predict_text = numpy.concatenate((texts_train, texts_val))\n",
    "predict_summ = numpy.concatenate((summs_train, summs_val))\n",
    "predict_y = numpy.concatenate((targets_train, targets_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11492/11492 [==============================] - 7s 629us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20658960570462936, 0.9388269976357155]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([predict_text, predict_summ], predict_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50/50 (clean/noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean data...\n",
      "...done!\n",
      "Read in candidate noise points...\n",
      "2872\n",
      "(2872,)\n",
      "(11490, 2)\n",
      "(2872, 2)\n",
      "...done!\n",
      "Preprocess clean data, i.e. remove <s> and </s>...\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/oala/Documents/MT/data/datasets/finished_files/test.bin\"\n",
    "noise_candidates_path = '/home/oala/Documents/MT/noising/4-beam-PGC-noise-on-train/pretrained_model_tf1.2.1/decode_train_400maxenc_4beam_35mindec_120maxdec_ckpt-238410/decoded/'\n",
    "nc_dist = (0.5,0.5)\n",
    "replace = False\n",
    "corr_sample = False\n",
    "separate = False\n",
    "band_width = 4\n",
    "dgp = \"random\"\n",
    "clean_2d, noise_2d = get_data(filename, nc_dist, replace, corr_sample, separate, band_width,noise_candidates_path, dgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11490, 2)\n",
      "(11488, 2)\n"
     ]
    }
   ],
   "source": [
    "print(clean_2d.shape)\n",
    "print(noise_2d.shape)\n",
    "#noise_2d = noise_2d[0:2] #here you reduce clean to 2 datapoints to get only noise!\n",
    "val_share = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dist:  0.4993200239351575\n",
      "val dist:  0.5025027203482045\n"
     ]
    }
   ],
   "source": [
    "texts_train, summs_train, targets_train, texts_val, summs_val, targets_val, tokenizer = \\\n",
    "    prep_data(clean_2d, noise_2d, max_features, val_share, maxlen_text, maxlen_summ,\n",
    "              load_tok=True, tok_path=tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the splits to get all data\n",
    "predict_text = numpy.concatenate((texts_train, texts_val))\n",
    "predict_summ = numpy.concatenate((summs_train, summs_val))\n",
    "predict_y = numpy.concatenate((targets_train, targets_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22978/22978 [==============================] - 14s 623us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3952894529908317, 0.8331882612223164]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([predict_text, predict_summ], predict_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0/100 (clean/noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clean data...\n",
      "...done!\n",
      "Read in candidate noise points...\n",
      "2872\n",
      "(2872,)\n",
      "(11490, 2)\n",
      "(2872, 2)\n",
      "...done!\n",
      "Preprocess clean data, i.e. remove <s> and </s>...\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/oala/Documents/MT/data/datasets/finished_files/test.bin\"\n",
    "noise_candidates_path = '/home/oala/Documents/MT/noising/4-beam-PGC-noise-on-train/pretrained_model_tf1.2.1/decode_train_400maxenc_4beam_35mindec_120maxdec_ckpt-238410/decoded/'\n",
    "nc_dist = (0.5,0.5)\n",
    "replace = False\n",
    "corr_sample = False\n",
    "separate = False\n",
    "band_width = 4\n",
    "dgp = \"random\"\n",
    "clean_2d, noise_2d = get_data(filename, nc_dist, replace, corr_sample, separate, band_width,noise_candidates_path, dgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11490, 2)\n",
      "(11488, 2)\n"
     ]
    }
   ],
   "source": [
    "print(clean_2d.shape)\n",
    "print(noise_2d.shape)\n",
    "clean_2d = clean_2d[0:2] #here you reduce clean to 2 datapoints to get only noise!\n",
    "val_share = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dist:  0.9997824194952132\n",
      "val dist:  1.0\n"
     ]
    }
   ],
   "source": [
    "texts_train, summs_train, targets_train, texts_val, summs_val, targets_val, tokenizer = \\\n",
    "    prep_data(clean_2d, noise_2d, max_features, val_share, maxlen_text, maxlen_summ,\n",
    "              load_tok=True, tok_path=tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the splits to get all data\n",
    "predict_text = numpy.concatenate((texts_train, texts_val))\n",
    "predict_summ = numpy.concatenate((summs_train, summs_val))\n",
    "predict_y = numpy.concatenate((targets_train, targets_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490/11490 [==============================] - 7s 622us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.587638956993118, 0.7233246312751471]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([predict_text, predict_summ], predict_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_clean_preds = numpy.ndarray((reference_preds.shape[0],1), dtype='int')\n",
    "pure_clean_preds[reference_preds<0.5] = 0\n",
    "pure_clean_preds[reference_preds>=0.5] = 1\n",
    "pure_clean_preds_one_hot = numpy.zeros((pure_clean_preds.shape[0],2))\n",
    "pure_clean_preds_one_hot[numpy.arange(reference_preds.shape[0]),pure_clean_preds[:,0]]=1\n",
    "pure_clean_targets_one_hot = numpy.ones((pure_clean_preds.shape[0],2))\n",
    "pure_clean_targets_one_hot[:,1]=0\n",
    "\n",
    "one = model.predict([predict_text, predict_summ], batch_size=batch_size)\n",
    "pure_noise_preds = numpy.ndarray((one.shape[0],1), dtype='int')\n",
    "pure_noise_preds[one<0.5] = 0\n",
    "pure_noise_preds[one>=0.5] = 1\n",
    "pure_noise_preds_one_hot = numpy.zeros((pure_noise_preds.shape[0],2))\n",
    "pure_noise_preds_one_hot[numpy.arange(one.shape[0]),pure_noise_preds[:,0]]=1\n",
    "pure_noise_targets_one_hot = numpy.ones((pure_noise_preds.shape[0],2))\n",
    "pure_noise_targets_one_hot[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9898.,    0.],\n",
       "       [1592.,    0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_clean_preds_one_hot.T @ pure_clean_targets_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.,  1302.],\n",
       "       [    0., 10188.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_noise_preds_one_hot.T @ pure_noise_targets_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.999446  ],\n",
       "       [0.33823976],\n",
       "       [0.8246137 ],\n",
       "       ...,\n",
       "       [0.98373276],\n",
       "       [0.99958295],\n",
       "       [0.99338466]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([predict_text, predict_summ], batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
